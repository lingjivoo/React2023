# REACT 2023 Multimodal Challenge
[[Homepage]](https://sites.google.com/cam.ac.uk/react2023/home)  [[Reference Paper]](https://arxiv.org/abs/2302.06514) [[Code]](https://github.com/lingjivoo/React2023)


This repository provides baseline methods for the [REACT 2023 Multimodal Challenge](https://sites.google.com/cam.ac.uk/react2023/home)

### Challenge Description
Human behavioural responses are stimulated by their environment (or context), and people will inductively process the stimulus and modify their interactions to produce an appropriate response. When facing the same stimulus, different facial reactions could be triggered across not only different subjects but also the same subjects under different contexts. The Multimodal Multiple Appropriate Facial Reaction Generation Challenge (REACT 2023) is a satellite event of ACM MM 2023, (Ottawa, Canada, October 2023), which aims at comparison of multimedia processing and machine learning methods for automatic human facial reaction generation under different dyadic interaction scenarios. The goal of the Challenge is to provide the first benchmark test set for multimodal information processing and to bring together the audio, visual and audio-visual affective computing communities, to compare the relative merits of the approaches to automatic appropriate facial reaction generation under well-defined conditions. 


#### Task 1 - Offline Appropriate Facial Reaction Generation
This task aims to develop a machine learning model that takes the entire speaker behaviour sequence as the input, and generates multiple appropriate and realistic / naturalistic spatio-temporal facial reactions, consisting of AUs, facial expressions, valence and arousal state representing the predicted facial reaction. As a result,  facial reactions are required to be generated for the task given each input speaker behaviour. 


#### Task 2 - Online Appropriate Facial Reaction Generation
This task aims to develop a machine learning model that estimates each frame, rather than taking all frames into consideration. The model is expected to gradually generate all facial reaction frames to form multiple appropriate and realistic / naturalistic spatio-temporal facial reactions consisting of AUs, facial expressions, valence and arousal state representing the predicted facial reaction. As a result,  facial reactions are required to be generated for the task given each input speaker behaviour. 


## ğŸ› ï¸ Installation

### Basic requirements

- Python 3.8+ 
- PyTorch 1.9+
- CUDA 11.1+ 

### Install Python dependencies

```shell
conda create -n react python=3.8
conda activate react
pip install -r requirements.txt
```


## ğŸ‘¨â€ğŸ« Get Started 


Data organization (`data/`) is listed below:
```
data
â”œâ”€â”€ test
â”œâ”€â”€ val
â”œâ”€â”€ train
   â”œâ”€â”€ Video_files
       â”œâ”€â”€ NoXI
           â”œâ”€â”€ 010_2016-03-25_Paris
               â”œâ”€â”€ Expert_video
               â”œâ”€â”€ Novice_video
                   â”œâ”€â”€ 1
                       â”œâ”€â”€ 1.png
                       â”œâ”€â”€ ....
                       â”œâ”€â”€ 751.png
                   â”œâ”€â”€ ....
           â”œâ”€â”€ ....
       â”œâ”€â”€ RECOLA
       â”œâ”€â”€ UDIVA
   â”œâ”€â”€ Audio_files
       â”œâ”€â”€ NoXI
       â”œâ”€â”€ RECOLA
           â”œâ”€â”€ group-1
               â”œâ”€â”€ P25 
               â”œâ”€â”€ P26
                   â”œâ”€â”€ 1.wav
                   â”œâ”€â”€ ....
           â”œâ”€â”€ group-2
           â”œâ”€â”€ group-3
       â”œâ”€â”€ UDIVA
   â”œâ”€â”€ Emotion
       â”œâ”€â”€ NoXI
       â”œâ”€â”€ RECOLA
           â”œâ”€â”€ group-1
               â”œâ”€â”€ P25 
               â”œâ”€â”€ P26
                   â”œâ”€â”€ 1.csv
                   â”œâ”€â”€ ....
           â”œâ”€â”€ group-2
           â”œâ”€â”€ group-3
       â”œâ”€â”€ UDIVA
   â”œâ”€â”€ 3D_FV_files
       â”œâ”€â”€ NoXI
       â”œâ”€â”€ RECOLA
           â”œâ”€â”€ group-1
               â”œâ”€â”€ P25 
               â”œâ”€â”€ P26
                   â”œâ”€â”€ 1.npy
                   â”œâ”€â”€ ....
           â”œâ”€â”€ group-2
           â”œâ”€â”€ group-3
       â”œâ”€â”€ UDIVA
            
```



